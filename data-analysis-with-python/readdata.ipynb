{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655a8f96",
   "metadata": {},
   "source": [
    "# Reading Data from Various Data Sources using Pandas\n",
    "\n",
    "📌 **Objective:**  \n",
    "Learn how to read data from different file formats and sources into a Pandas DataFrame —  \n",
    "including CSV, Excel, JSON, SQL, HTML, and APIs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 1. The Universal Loader — `pd.read_*()`\n",
    "\n",
    "Pandas provides a powerful set of functions prefixed with `read_`  \n",
    "for importing data from almost any source.\n",
    "\n",
    "\\[\n",
    "\\text{DataFrame} = pd.read\\_*(\\text{source})\n",
    "\\]\n",
    "\n",
    "Here are some of the most common ones:\n",
    "\n",
    "| Format | Function | Example |\n",
    "|:--------|:-----------|:--------------------------------|\n",
    "| CSV | `pd.read_csv()` | `'data.csv'` |\n",
    "| Excel | `pd.read_excel()` | `'data.xlsx'` |\n",
    "| JSON | `pd.read_json()` | `'data.json'` |\n",
    "| SQL | `pd.read_sql()` | `'SELECT * FROM table'` |\n",
    "| HTML | `pd.read_html()` | `'https://example.com'` |\n",
    "| Clipboard | `pd.read_clipboard()` | copy–paste data |\n",
    "| Parquet | `pd.read_parquet()` | `'data.parquet'` |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 2. Reading CSV Files\n",
    "\n",
    "CSV (Comma-Separated Values) is the most common format for structured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "423792e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836fae5",
   "metadata": {},
   "source": [
    "💡 Converting JSON into Data frame\n",
    "\n",
    "> _Note:_ This markdown was expanded for clarity. Replace with more specific notes if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fd57a",
   "metadata": {},
   "source": [
    "# 🔹 Reading JSON data\n",
    "\n",
    "**Purpose:** Load JSON files or API responses and normalize nested structures with `pd.json_normalize()`.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78b2f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>email</th>\n",
       "      <th>job_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>james@gmail.com</td>\n",
       "      <td>{'title1': 'Team Lead', 'title2': 'Sr. Develop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_name            email  \\\n",
       "0         James  james@gmail.com   \n",
       "\n",
       "                                         job_profile  \n",
       "0  {'title1': 'Team Lead', 'title2': 'Sr. Develop...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧾 Read structured data from a JSON file or API response\n",
    "\n",
    "data = '{\"employee_name\": \"James\", \"email\": \"james@gmail.com\", \"job_profile\": [{\"title1\":\"Team Lead\", \"title2\":\"Sr. Developer\"}]}'\n",
    "df = pd.read_json(StringIO(data))  # Load JSON into DataFrame\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af924f0d",
   "metadata": {},
   "source": [
    "💡 Coverting Data frame to Json\n",
    "\n",
    "> _Note:_ This markdown was expanded for clarity. Replace with more specific notes if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7006209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"employee_name\":{\"0\":\"James\"},\"email\":{\"0\":\"james@gmail.com\"},\"job_profile\":{\"0\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "display(df.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3c539",
   "metadata": {},
   "source": [
    "💡 Coverting Data frame to Json (with orient as `index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bc3087d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "display(df.to_json(orient='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6a442",
   "metadata": {},
   "source": [
    "💡 Coverting Data frame to Json (with orient as `records`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a1dc1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "display(df.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550453a",
   "metadata": {},
   "source": [
    "💡 This is how we can read a specific data from a specific URL, provided that data is comma seperated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a77578",
   "metadata": {},
   "source": [
    "# 🔹 Reading CSV files\n",
    "\n",
    "**Purpose:** Load CSV files into a DataFrame using `pd.read_csv()` with common options.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5ab2726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧠 Load data from a CSV file into a DataFrame and inspect the first few rows\n",
    "\n",
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None)  # Read CSV file into a pandas DataFrame\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40f648",
   "metadata": {},
   "source": [
    "💡 Converting this dataframe back to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a11cf",
   "metadata": {},
   "source": [
    "# 🔹 Writing / Exporting data\n",
    "\n",
    "**Purpose:** Export DataFrames to CSV/Excel/SQL using `to_csv()`, `to_excel()`, and `to_sql()`.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "36ebba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 Export DataFrame to a CSV file for reporting or sharing\n",
    "\n",
    "df.to_csv('wine.csv')  # Export DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c354cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: html5lib in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from html5lib) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from beautifulsoup4) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "!pip install lxml\n",
    "!pip install html5lib\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e1956",
   "metadata": {},
   "source": [
    "💡 Reading a data from a URL\n",
    "\n",
    "> _Note:_ This markdown was expanded for clarity. Replace with more specific notes if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db41b8",
   "metadata": {},
   "source": [
    "# 🔹 Reading HTML tables from the web\n",
    "\n",
    "**Purpose:** Extract `<table>` elements from webpages using `pd.read_html()`; use `requests` + `StringIO` when needed.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35f74341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                            Bank Name                City  \\\n",
       " 0                        The Santa Anna National Bank          Santa Anna   \n",
       " 1                                Pulaski Savings Bank             Chicago   \n",
       " 2                  The First National Bank of Lindsay             Lindsay   \n",
       " 3               Republic First Bank dba Republic Bank        Philadelphia   \n",
       " 4                                       Citizens Bank            Sac City   \n",
       " 5                            Heartland Tri-State Bank             Elkhart   \n",
       " 6                                 First Republic Bank       San Francisco   \n",
       " 7                                      Signature Bank            New York   \n",
       " 8                                 Silicon Valley Bank         Santa Clara   \n",
       " 9                                   Almena State Bank              Almena   \n",
       " 10                         First City Bank of Florida   Fort Walton Beach   \n",
       " 11                               The First State Bank       Barboursville   \n",
       " 12                                 Ericson State Bank             Ericson   \n",
       " 13                   City National Bank of New Jersey              Newark   \n",
       " 14                                      Resolute Bank              Maumee   \n",
       " 15                              Louisa Community Bank              Louisa   \n",
       " 16                               The Enloe State Bank              Cooper   \n",
       " 17                Washington Federal Bank for Savings             Chicago   \n",
       " 18    The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       " 19                                Fayette County Bank          Saint Elmo   \n",
       " 20  Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       " 21                                     First NBC Bank         New Orleans   \n",
       " 22                                      Proficio Bank  Cottonwood Heights   \n",
       " 23                      Seaway Bank and Trust Company             Chicago   \n",
       " 24                             Harvest Community Bank          Pennsville   \n",
       " \n",
       "             State   Cert                Acquiring Institution  \\\n",
       " 0           Texas   5520            Coleman County State Bank   \n",
       " 1        Illinois  28611                      Millennium Bank   \n",
       " 2        Oklahoma   4134               First Bank & Trust Co.   \n",
       " 3    Pennsylvania  27332    Fulton Bank, National Association   \n",
       " 4            Iowa   8758            Iowa Trust & Savings Bank   \n",
       " 5          Kansas  25851               Dream First Bank, N.A.   \n",
       " 6      California  59017            JPMorgan Chase Bank, N.A.   \n",
       " 7        New York  57053                  Flagstar Bank, N.A.   \n",
       " 8      California  24735  First Citizens Bank & Trust Company   \n",
       " 9          Kansas  15426                          Equity Bank   \n",
       " 10        Florida  16748            United Fidelity Bank, fsb   \n",
       " 11  West Virginia  14361                       MVB Bank, Inc.   \n",
       " 12       Nebraska  18265           Farmers and Merchants Bank   \n",
       " 13     New Jersey  21111                      Industrial Bank   \n",
       " 14           Ohio  58317                   Buckeye State Bank   \n",
       " 15       Kentucky  58112    Kentucky Farmers Bank Corporation   \n",
       " 16          Texas  10716                   Legend Bank, N. A.   \n",
       " 17       Illinois  30570                   Royal Savings Bank   \n",
       " 18         Kansas  17719                          Conway Bank   \n",
       " 19       Illinois   1802            United Fidelity Bank, fsb   \n",
       " 20      Wisconsin  30003  First-Citizens Bank & Trust Company   \n",
       " 21      Louisiana  58302                         Whitney Bank   \n",
       " 22           Utah  35495                    Cache Valley Bank   \n",
       " 23       Illinois  19328                  State Bank of Texas   \n",
       " 24     New Jersey  34951  First-Citizens Bank & Trust Company   \n",
       " \n",
       "          Closing Date  Fund  Sort ascending  \n",
       " 0       June 27, 2025                 10549  \n",
       " 1    January 17, 2025                 10548  \n",
       " 2    October 18, 2024                 10547  \n",
       " 3      April 26, 2024                 10546  \n",
       " 4    November 3, 2023                 10545  \n",
       " 5       July 28, 2023                 10544  \n",
       " 6         May 1, 2023                 10543  \n",
       " 7      March 12, 2023                 10540  \n",
       " 8      March 10, 2023                 10539  \n",
       " 9    October 23, 2020                 10538  \n",
       " 10   October 16, 2020                 10537  \n",
       " 11      April 3, 2020                 10536  \n",
       " 12  February 14, 2020                 10535  \n",
       " 13   November 1, 2019                 10534  \n",
       " 14   October 25, 2019                 10533  \n",
       " 15   October 25, 2019                 10532  \n",
       " 16       May 31, 2019                 10531  \n",
       " 17  December 15, 2017                 10530  \n",
       " 18   October 13, 2017                 10529  \n",
       " 19       May 26, 2017                 10528  \n",
       " 20        May 5, 2017                 10527  \n",
       " 21     April 28, 2017                 10526  \n",
       " 22      March 3, 2017                 10525  \n",
       " 23   January 27, 2017                 10524  \n",
       " 24   January 13, 2017                 10523  ]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🌐 Extract tabular data from an HTML webpage using `pd.read_html()`\n",
    "\n",
    "url=\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\"\n",
    "\n",
    "fdic_df = pd.read_html(url)  # Parse HTML and extract tables as DataFrames\n",
    "display(fdic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5018cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Cert</th>\n",
       "      <th>Acquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "      <th>Fund  Sort ascending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Santa Anna National Bank</td>\n",
       "      <td>Santa Anna</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5520</td>\n",
       "      <td>Coleman County State Bank</td>\n",
       "      <td>June 27, 2025</td>\n",
       "      <td>10549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pulaski Savings Bank</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>28611</td>\n",
       "      <td>Millennium Bank</td>\n",
       "      <td>January 17, 2025</td>\n",
       "      <td>10548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The First National Bank of Lindsay</td>\n",
       "      <td>Lindsay</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>4134</td>\n",
       "      <td>First Bank &amp; Trust Co.</td>\n",
       "      <td>October 18, 2024</td>\n",
       "      <td>10547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republic First Bank dba Republic Bank</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>27332</td>\n",
       "      <td>Fulton Bank, National Association</td>\n",
       "      <td>April 26, 2024</td>\n",
       "      <td>10546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citizens Bank</td>\n",
       "      <td>Sac City</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>8758</td>\n",
       "      <td>Iowa Trust &amp; Savings Bank</td>\n",
       "      <td>November 3, 2023</td>\n",
       "      <td>10545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heartland Tri-State Bank</td>\n",
       "      <td>Elkhart</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>25851</td>\n",
       "      <td>Dream First Bank, N.A.</td>\n",
       "      <td>July 28, 2023</td>\n",
       "      <td>10544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>First Republic Bank</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>59017</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>May 1, 2023</td>\n",
       "      <td>10543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Signature Bank</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>57053</td>\n",
       "      <td>Flagstar Bank, N.A.</td>\n",
       "      <td>March 12, 2023</td>\n",
       "      <td>10540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>24735</td>\n",
       "      <td>First Citizens Bank &amp; Trust Company</td>\n",
       "      <td>March 10, 2023</td>\n",
       "      <td>10539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Almena State Bank</td>\n",
       "      <td>Almena</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>15426</td>\n",
       "      <td>Equity Bank</td>\n",
       "      <td>October 23, 2020</td>\n",
       "      <td>10538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>First City Bank of Florida</td>\n",
       "      <td>Fort Walton Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>16748</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>October 16, 2020</td>\n",
       "      <td>10537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The First State Bank</td>\n",
       "      <td>Barboursville</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14361</td>\n",
       "      <td>MVB Bank, Inc.</td>\n",
       "      <td>April 3, 2020</td>\n",
       "      <td>10536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ericson State Bank</td>\n",
       "      <td>Ericson</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>18265</td>\n",
       "      <td>Farmers and Merchants Bank</td>\n",
       "      <td>February 14, 2020</td>\n",
       "      <td>10535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>City National Bank of New Jersey</td>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>21111</td>\n",
       "      <td>Industrial Bank</td>\n",
       "      <td>November 1, 2019</td>\n",
       "      <td>10534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Resolute Bank</td>\n",
       "      <td>Maumee</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>58317</td>\n",
       "      <td>Buckeye State Bank</td>\n",
       "      <td>October 25, 2019</td>\n",
       "      <td>10533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Louisa Community Bank</td>\n",
       "      <td>Louisa</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>58112</td>\n",
       "      <td>Kentucky Farmers Bank Corporation</td>\n",
       "      <td>October 25, 2019</td>\n",
       "      <td>10532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Enloe State Bank</td>\n",
       "      <td>Cooper</td>\n",
       "      <td>Texas</td>\n",
       "      <td>10716</td>\n",
       "      <td>Legend Bank, N. A.</td>\n",
       "      <td>May 31, 2019</td>\n",
       "      <td>10531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington Federal Bank for Savings</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>30570</td>\n",
       "      <td>Royal Savings Bank</td>\n",
       "      <td>December 15, 2017</td>\n",
       "      <td>10530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Farmers and Merchants State Bank of Argonia</td>\n",
       "      <td>Argonia</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>17719</td>\n",
       "      <td>Conway Bank</td>\n",
       "      <td>October 13, 2017</td>\n",
       "      <td>10529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fayette County Bank</td>\n",
       "      <td>Saint Elmo</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1802</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>May 26, 2017</td>\n",
       "      <td>10528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Guaranty Bank, (d/b/a BestBank in Georgia &amp; Mi...</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>30003</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>May 5, 2017</td>\n",
       "      <td>10527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>First NBC Bank</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>58302</td>\n",
       "      <td>Whitney Bank</td>\n",
       "      <td>April 28, 2017</td>\n",
       "      <td>10526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Proficio Bank</td>\n",
       "      <td>Cottonwood Heights</td>\n",
       "      <td>Utah</td>\n",
       "      <td>35495</td>\n",
       "      <td>Cache Valley Bank</td>\n",
       "      <td>March 3, 2017</td>\n",
       "      <td>10525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Seaway Bank and Trust Company</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>19328</td>\n",
       "      <td>State Bank of Texas</td>\n",
       "      <td>January 27, 2017</td>\n",
       "      <td>10524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Harvest Community Bank</td>\n",
       "      <td>Pennsville</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34951</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>January 13, 2017</td>\n",
       "      <td>10523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Bank Name                City  \\\n",
       "0                        The Santa Anna National Bank          Santa Anna   \n",
       "1                                Pulaski Savings Bank             Chicago   \n",
       "2                  The First National Bank of Lindsay             Lindsay   \n",
       "3               Republic First Bank dba Republic Bank        Philadelphia   \n",
       "4                                       Citizens Bank            Sac City   \n",
       "5                            Heartland Tri-State Bank             Elkhart   \n",
       "6                                 First Republic Bank       San Francisco   \n",
       "7                                      Signature Bank            New York   \n",
       "8                                 Silicon Valley Bank         Santa Clara   \n",
       "9                                   Almena State Bank              Almena   \n",
       "10                         First City Bank of Florida   Fort Walton Beach   \n",
       "11                               The First State Bank       Barboursville   \n",
       "12                                 Ericson State Bank             Ericson   \n",
       "13                   City National Bank of New Jersey              Newark   \n",
       "14                                      Resolute Bank              Maumee   \n",
       "15                              Louisa Community Bank              Louisa   \n",
       "16                               The Enloe State Bank              Cooper   \n",
       "17                Washington Federal Bank for Savings             Chicago   \n",
       "18    The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       "19                                Fayette County Bank          Saint Elmo   \n",
       "20  Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       "21                                     First NBC Bank         New Orleans   \n",
       "22                                      Proficio Bank  Cottonwood Heights   \n",
       "23                      Seaway Bank and Trust Company             Chicago   \n",
       "24                             Harvest Community Bank          Pennsville   \n",
       "\n",
       "            State   Cert                Acquiring Institution  \\\n",
       "0           Texas   5520            Coleman County State Bank   \n",
       "1        Illinois  28611                      Millennium Bank   \n",
       "2        Oklahoma   4134               First Bank & Trust Co.   \n",
       "3    Pennsylvania  27332    Fulton Bank, National Association   \n",
       "4            Iowa   8758            Iowa Trust & Savings Bank   \n",
       "5          Kansas  25851               Dream First Bank, N.A.   \n",
       "6      California  59017            JPMorgan Chase Bank, N.A.   \n",
       "7        New York  57053                  Flagstar Bank, N.A.   \n",
       "8      California  24735  First Citizens Bank & Trust Company   \n",
       "9          Kansas  15426                          Equity Bank   \n",
       "10        Florida  16748            United Fidelity Bank, fsb   \n",
       "11  West Virginia  14361                       MVB Bank, Inc.   \n",
       "12       Nebraska  18265           Farmers and Merchants Bank   \n",
       "13     New Jersey  21111                      Industrial Bank   \n",
       "14           Ohio  58317                   Buckeye State Bank   \n",
       "15       Kentucky  58112    Kentucky Farmers Bank Corporation   \n",
       "16          Texas  10716                   Legend Bank, N. A.   \n",
       "17       Illinois  30570                   Royal Savings Bank   \n",
       "18         Kansas  17719                          Conway Bank   \n",
       "19       Illinois   1802            United Fidelity Bank, fsb   \n",
       "20      Wisconsin  30003  First-Citizens Bank & Trust Company   \n",
       "21      Louisiana  58302                         Whitney Bank   \n",
       "22           Utah  35495                    Cache Valley Bank   \n",
       "23       Illinois  19328                  State Bank of Texas   \n",
       "24     New Jersey  34951  First-Citizens Bank & Trust Company   \n",
       "\n",
       "         Closing Date  Fund  Sort ascending  \n",
       "0       June 27, 2025                 10549  \n",
       "1    January 17, 2025                 10548  \n",
       "2    October 18, 2024                 10547  \n",
       "3      April 26, 2024                 10546  \n",
       "4    November 3, 2023                 10545  \n",
       "5       July 28, 2023                 10544  \n",
       "6         May 1, 2023                 10543  \n",
       "7      March 12, 2023                 10540  \n",
       "8      March 10, 2023                 10539  \n",
       "9    October 23, 2020                 10538  \n",
       "10   October 16, 2020                 10537  \n",
       "11      April 3, 2020                 10536  \n",
       "12  February 14, 2020                 10535  \n",
       "13   November 1, 2019                 10534  \n",
       "14   October 25, 2019                 10533  \n",
       "15   October 25, 2019                 10532  \n",
       "16       May 31, 2019                 10531  \n",
       "17  December 15, 2017                 10530  \n",
       "18   October 13, 2017                 10529  \n",
       "19       May 26, 2017                 10528  \n",
       "20        May 5, 2017                 10527  \n",
       "21     April 28, 2017                 10526  \n",
       "22      March 3, 2017                 10525  \n",
       "23   January 27, 2017                 10524  \n",
       "24   January 13, 2017                 10523  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "fdic_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abac90d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from requests) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476dc46",
   "metadata": {},
   "source": [
    "# 🔹 Reading HTML tables from the web\n",
    "\n",
    "**Purpose:** Extract `<table>` elements from webpages using `pd.read_html()`; use `requests` + `StringIO` when needed.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6123c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/rst47yl90f74cf3frj58cvw00000gn/T/ipykernel_6863/1555488421.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text, match=\"Country\", header=0)  # Parse HTML and extract tables as DataFrames\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobile country code</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO 3166</th>\n",
       "      <th>Mobile network codes</th>\n",
       "      <th>National MNC authority</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>A Abkhazia</td>\n",
       "      <td>GE-AB</td>\n",
       "      <td>List of mobile network codes in Abkhazia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCC is not listed by ITU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>List of mobile network codes in Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>List of mobile network codes in Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>List of mobile network codes in Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544</td>\n",
       "      <td>American Samoa (United States of America)</td>\n",
       "      <td>AS</td>\n",
       "      <td>List of mobile network codes in American Samoa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mobile country code                                    Country ISO 3166  \\\n",
       "0                  289                                 A Abkhazia    GE-AB   \n",
       "1                  412                                Afghanistan       AF   \n",
       "2                  276                                    Albania       AL   \n",
       "3                  603                                    Algeria       DZ   \n",
       "4                  544  American Samoa (United States of America)       AS   \n",
       "\n",
       "                             Mobile network codes National MNC authority  \\\n",
       "0        List of mobile network codes in Abkhazia                    NaN   \n",
       "1     List of mobile network codes in Afghanistan                    NaN   \n",
       "2         List of mobile network codes in Albania                    NaN   \n",
       "3         List of mobile network codes in Algeria                    NaN   \n",
       "4  List of mobile network codes in American Samoa                    NaN   \n",
       "\n",
       "                    Remarks  \n",
       "0  MCC is not listed by ITU  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🌐 Extract tabular data from an HTML webpage using `pd.read_html()`\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL of the page\n",
    "url = \"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "\n",
    "# Add custom headers to mimic a real browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "                  \"AppleWebKit/605.1.15 (KHTML, like Gecko) \"\n",
    "                  \"Version/17.0 Safari/605.1.15\"\n",
    "}\n",
    "\n",
    "# Fetch the HTML content\n",
    "response = requests.get(url, headers=headers)  # Perform HTTP GET request (include headers to avoid 403)\n",
    "response.raise_for_status()  # Raise error if request fails\n",
    "\n",
    "# Parse HTML with pandas\n",
    "tables = pd.read_html(response.text, match=\"Country\", header=0)  # Parse HTML and extract tables as DataFrames\n",
    "\n",
    "# Display first table\n",
    "df = tables[0]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad05775",
   "metadata": {},
   "source": [
    "### ✅ Explanation\n",
    "| Step | Action                     | Purpose                     |\n",
    "| :--- | :------------------------- | :-------------------------- |\n",
    "| 1️⃣  | Use `requests.get()`       | Manual request with control |\n",
    "| 2️⃣  | Add `User-Agent` header    | Pretend to be a browser     |\n",
    "| 3️⃣  | `response.text`            | Get HTML as a string        |\n",
    "| 4️⃣  | `pd.read_html()`           | Parse HTML content directly |\n",
    "| 5️⃣  | Optional `match=\"Country\"` | Filter the right table      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a5f77",
   "metadata": {},
   "source": [
    "🧠 Extra Tip: Identify All Tables\n",
    "\n",
    "If you’re unsure which table to extract:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342a2ac",
   "metadata": {},
   "source": [
    "# 🔹 Reading HTML tables from the web\n",
    "\n",
    "**Purpose:** Extract `<table>` elements from webpages using `pd.read_html()`; use `requests` + `StringIO` when needed.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a4e5e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Table 0 shape: (4, 7)\n",
      "🔹 Table 1 shape: (252, 6)\n",
      "🔹 Table 2 shape: (104, 7)\n",
      "🔹 Table 3 shape: (1, 7)\n",
      "🔹 Table 4 shape: (10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/rst47yl90f74cf3frj58cvw00000gn/T/ipykernel_6863/2281944245.py:3: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  for i, table in enumerate(pd.read_html(response.text)):  # Parse HTML and extract tables as DataFrames\n"
     ]
    }
   ],
   "source": [
    "# 🌐 Extract tabular data from an HTML webpage using `pd.read_html()`\n",
    "\n",
    "for i, table in enumerate(pd.read_html(response.text)):  # Parse HTML and extract tables as DataFrames\n",
    "    print(f\"🔹 Table {i} shape:\", table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321de6c",
   "metadata": {},
   "source": [
    "`/var/folders/vf/rst47yl90f74cf3frj58cvw00000gn/T/ipykernel_6863/3170680250.py:18`: **FutureWarning**: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
    "  tables = pd.read_html(response.text, match=\"Country\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23d289",
   "metadata": {},
   "source": [
    "# 🔹 Reading HTML tables from the web\n",
    "\n",
    "**Purpose:** Extract `<table>` elements from webpages using `pd.read_html()`; use `requests` + `StringIO` when needed.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3f479b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobile country code</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO 3166</th>\n",
       "      <th>Mobile network codes</th>\n",
       "      <th>National MNC authority</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>A Abkhazia</td>\n",
       "      <td>GE-AB</td>\n",
       "      <td>List of mobile network codes in Abkhazia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCC is not listed by ITU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>List of mobile network codes in Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>List of mobile network codes in Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>List of mobile network codes in Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544</td>\n",
       "      <td>American Samoa (United States of America)</td>\n",
       "      <td>AS</td>\n",
       "      <td>List of mobile network codes in American Samoa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mobile country code                                    Country ISO 3166  \\\n",
       "0                  289                                 A Abkhazia    GE-AB   \n",
       "1                  412                                Afghanistan       AF   \n",
       "2                  276                                    Albania       AL   \n",
       "3                  603                                    Algeria       DZ   \n",
       "4                  544  American Samoa (United States of America)       AS   \n",
       "\n",
       "                             Mobile network codes National MNC authority  \\\n",
       "0        List of mobile network codes in Abkhazia                    NaN   \n",
       "1     List of mobile network codes in Afghanistan                    NaN   \n",
       "2         List of mobile network codes in Albania                    NaN   \n",
       "3         List of mobile network codes in Algeria                    NaN   \n",
       "4  List of mobile network codes in American Samoa                    NaN   \n",
       "\n",
       "                    Remarks  \n",
       "0  MCC is not listed by ITU  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🌐 Extract tabular data from an HTML webpage using `pd.read_html()`\n",
    "\n",
    "import requests\n",
    "from io import StringIO   # ✅ New import for wrapping HTML string\n",
    "\n",
    "# Target URL\n",
    "url = \"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "\n",
    "# Spoof a browser user-agent (Wikipedia blocks raw bot requests)\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/605.1.15 (KHTML, like Gecko) \"\n",
    "        \"Version/17.0 Safari/605.1.15\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Fetch the HTML content safely\n",
    "response = requests.get(url, headers=headers)  # Perform HTTP GET request (include headers to avoid 403)\n",
    "response.raise_for_status()  # Raise error if the request fails\n",
    "\n",
    "# ✅ Wrap the HTML content in a StringIO object to avoid the FutureWarning\n",
    "html_content = StringIO(response.text)\n",
    "\n",
    "# Read HTML tables from the page\n",
    "tables = pd.read_html(html_content, match=\"Country\", header=0)  # Parse HTML and extract tables as DataFrames\n",
    "\n",
    "# Extract the main table\n",
    "df = tables[0]\n",
    "\n",
    "# Display preview\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd76b0",
   "metadata": {},
   "source": [
    "# 🧩 Inspecting Multiple Tables from a Webpage\n",
    "\n",
    "📌 **Objective:**  \n",
    "When a webpage contains several `<table>` elements,  \n",
    "`pd.read_html()` returns **a list of DataFrames** — one for each detected table.\n",
    "\n",
    "We can iterate through this list to inspect them all  \n",
    "and choose the one we actually need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c9579",
   "metadata": {},
   "source": [
    "# 🔹 Reading HTML tables from the web\n",
    "\n",
    "**Purpose:** Extract `<table>` elements from webpages using `pd.read_html()`; use `requests` + `StringIO` when needed.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e6dfd465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Table 0: shape = (4, 7)\n",
      "🔹 Table 1: shape = (252, 6)\n",
      "🔹 Table 2: shape = (104, 7)\n",
      "🔹 Table 3: shape = (1, 7)\n",
      "🔹 Table 4: shape = (10, 2)\n"
     ]
    }
   ],
   "source": [
    "# 🌐 Extract tabular data from an HTML webpage using `pd.read_html()`\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/605.1.15 (KHTML, like Gecko) \"\n",
    "        \"Version/17.0 Safari/605.1.15\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Fetch HTML content\n",
    "response = requests.get(url, headers=headers)  # Perform HTTP GET request (include headers to avoid 403)\n",
    "html_content = StringIO(response.text)\n",
    "\n",
    "# Read all tables from the page\n",
    "tables = pd.read_html(html_content)  # Parse HTML and extract tables as DataFrames\n",
    "\n",
    "# Iterate through all detected tables\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"🔹 Table {i}: shape = {table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "febd9a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/psundara/learn/python/python-series/.conda/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 🧱 Code cell — performs data manipulation or utility operation\n",
    "\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99616838",
   "metadata": {},
   "source": [
    "# 🔹 Reading Excel files\n",
    "\n",
    "**Purpose:** Load Excel sheets into DataFrames using `pd.read_excel()` and handle `sheet_name`.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffc8c7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prasanna Sundaram</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sundaram</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indra</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Age\n",
       "0  Prasanna Sundaram   35\n",
       "1           Sundaram   67\n",
       "2              Indra   61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📘 Read data from an Excel sheet using `pd.read_excel()` and preview results\n",
    "\n",
    "# sheet_name is optional\n",
    "df_excel = pd.read_excel('Book1.xlsx', sheet_name='Sheet1')  # Read Excel file or sheet into DataFrame\n",
    "display(df_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1b696",
   "metadata": {},
   "source": [
    "##  What is a Pickle File?\n",
    "\n",
    "Pickle is a **binary file format** used to serialize (save) Python objects so they can be  \n",
    "easily loaded later without losing structure, data types, or indexes.\n",
    "\n",
    "Unlike CSV or Excel:\n",
    "- It **preserves data types**\n",
    "- It’s **faster** to read/write\n",
    "- It’s **not human-readable** (binary format)\n",
    "\n",
    "$$[\n",
    "\\text{Save → Serialize (Pickle)} \\;\\;\\;\\; \\text{Load → Deserialize (Unpickle)}\n",
    "]$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837a77e",
   "metadata": {},
   "source": [
    "# 🔹 Pickle (serialize/deserialize DataFrames)\n",
    "\n",
    "**Purpose:** Save and load DataFrames quickly with `to_pickle()` / `pd.read_pickle()`; mention security caveat.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bcbf996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 Save DataFrame to a Pickle file for fast reload\n",
    "\n",
    "df_excel.to_pickle('df_excel.pkl')  # Serialize DataFrame to pickle file for fast I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c8ad7",
   "metadata": {},
   "source": [
    "💡 After executing this a pickle file named `df_excel.pkl` would be created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610fcff",
   "metadata": {},
   "source": [
    "# 🔹 Pickle (serialize/deserialize DataFrames)\n",
    "\n",
    "**Purpose:** Save and load DataFrames quickly with `to_pickle()` / `pd.read_pickle()`; mention security caveat.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e5ddc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prasanna Sundaram</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sundaram</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indra</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Age\n",
       "0  Prasanna Sundaram   35\n",
       "1           Sundaram   67\n",
       "2              Indra   61"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📂 Load a serialized DataFrame from a Pickle file\n",
    "\n",
    "pd.read_pickle('df_excel.pkl')  # Load DataFrame from pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026dea81",
   "metadata": {},
   "source": [
    "Pickle is typically **2x–10x faster** than CSV for both saving and loading large DataFrames.  \n",
    "It’s also **type-safe**, meaning integers remain integers, datetimes remain datetimes, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eeb54e",
   "metadata": {},
   "source": [
    "## 🔹 Notes & Best Practices\n",
    "\n",
    "| ⚙️ Scenario | Recommendation |\n",
    "|:-------------|:----------------|\n",
    "| Large data with frequent reloading | ✅ Use Pickle |\n",
    "| Need human-readable file | ❌ Avoid Pickle → Use CSV or Excel |\n",
    "| Cross-language sharing | ❌ Avoid Pickle (Python-only format) |\n",
    "| Quick local caching in analysis | ✅ Perfect use case |\n",
    "| Security | ⚠️ Never unpickle data from untrusted sources |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Alternative: Compressed Pickle Files\n",
    "\n",
    "You can save space using compression (gzip, bz2, zip, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0896576b",
   "metadata": {},
   "source": [
    "# 🔹 Pickle (serialize/deserialize DataFrames)\n",
    "\n",
    "**Purpose:** Save and load DataFrames quickly with `to_pickle()` / `pd.read_pickle()`; mention security caveat.\n",
    "\n",
    "*Auto-generated section header for clarity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "727ded58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prasanna Sundaram</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sundaram</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indra</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Age\n",
       "0  Prasanna Sundaram   35\n",
       "1           Sundaram   67\n",
       "2              Indra   61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 💾 Save DataFrame to a Pickle file for fast reload\n",
    "\n",
    "# Save pickle with gzip compression\n",
    "df_excel.to_pickle('df_excel.pkl.gz', compression='gzip')  # Serialize DataFrame to pickle file for fast I/O\n",
    "\n",
    "# Load compressed pickle\n",
    "df_gzip = pd.read_pickle('df_excel.pkl.gz', compression='gzip')  # Load DataFrame from pickle file\n",
    "display(df_gzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1feb9",
   "metadata": {},
   "source": [
    "✅ **Output:** Same as original, but file size is smaller.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧾 Summary Table\n",
    "\n",
    "| Operation | Method | Description |\n",
    "|:------------|:----------|:-------------|\n",
    "| Save as Pickle | `df.to_pickle('file.pkl')` | Serializes DataFrame |\n",
    "| Load Pickle | `pd.read_pickle('file.pkl')` | Deserializes DataFrame |\n",
    "| Compressed Pickle | `compression='gzip'` | Optional compression |\n",
    "| Compare Speed | CSV slower; Pickle faster | Type-safe & binary format |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Quick Recap\n",
    "\n",
    "🔹 `to_pickle()` saves your DataFrame in Python’s binary format  \n",
    "🔹 `pd.read_pickle()` loads it instantly  \n",
    "🔹 Much faster than CSV or Excel for large datasets  \n",
    "🔹 Best for intermediate caching or local analysis  \n",
    "🔹 Don’t use Pickle for sharing across platforms or untrusted sources\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
