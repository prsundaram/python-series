{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f5f950",
   "metadata": {},
   "source": [
    "# üß© Part-of-Speech (POS) Tagging\n",
    "\n",
    "> **Objective:**  \n",
    "> Identify the grammatical role of each word in a sentence ‚Äî  \n",
    "> e.g., whether it‚Äôs a **noun**, **verb**, **adjective**, **adverb**, etc.\n",
    "\n",
    "POS tagging helps machines understand **sentence structure** and **word meaning in context**,  \n",
    "which is essential for downstream tasks like lemmatization, parsing, NER, and text understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò 1. What is POS Tagging?\n",
    "\n",
    "**Definition:**  \n",
    "Part-of-Speech Tagging is the process of assigning a part of speech label (like *NN*, *VB*, *JJ*)  \n",
    "to each token in a sentence, based on both its **definition** and **context**.\n",
    "\n",
    "Formally, for a tokenized sequence $ T = [w_1, w_2, ..., w_n] $:\n",
    "\n",
    "$$\n",
    "\\text{POS}(w_i) = \\operatorname{tagger}(w_i, C_i)\n",
    "$$\n",
    "\n",
    "where $ C_i $ is the context window around word $ w_i $.\n",
    "\n",
    "---\n",
    "\n",
    "| Example | Word | POS Tag | Meaning |\n",
    "|----------|------|----------|----------|\n",
    "| The mice were running fast | The | DT | Determiner |\n",
    "| The mice were running fast | mice | NNS | Noun, plural |\n",
    "| The mice were running fast | were | VBD | Verb, past tense |\n",
    "| The mice were running fast | running | VBG | Verb, gerund |\n",
    "| The mice were running fast | fast | RB | Adverb |\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Key Idea\n",
    "A single word can take multiple POS tags depending on context:\n",
    "\n",
    "| Word | Sentence | POS | Meaning |\n",
    "|------|-----------|-----|----------|\n",
    "| play | I **play** cricket. | VB | Verb (action) |\n",
    "| play | The **play** was excellent. | NN | Noun (thing) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f29012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         The  ‚Üí  DT\n",
      "        mice  ‚Üí  NN\n",
      "        were  ‚Üí  VBD\n",
      "     running  ‚Üí  VBG\n",
      "      faster  ‚Üí  RBR\n",
      "         and  ‚Üí  CC\n",
      "         the  ‚Üí  DT\n",
      "      better  ‚Üí  JJR\n",
      "      runner  ‚Üí  NN\n",
      "         was  ‚Üí  VBD\n",
      "     finally  ‚Üí  RB\n",
      "   organized  ‚Üí  VBN\n",
      "           .  ‚Üí  .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The mice were running faster and the better runner was finally organized.\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "for word, tag in tags:\n",
    "    print(f\"{word:>12}  ‚Üí  {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8ad6c",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. POS Tag Sets (Penn Treebank)\n",
    "\n",
    "NLTK uses the **Penn Treebank POS Tag Set**,  \n",
    "a standardized collection of POS abbreviations.\n",
    "\n",
    "| Tag | Part of Speech | Example |\n",
    "|------|----------------|----------|\n",
    "| NN | Noun, singular | cat, boy |\n",
    "| NNS | Noun, plural | mice, cars |\n",
    "| VB | Verb, base | go, play |\n",
    "| VBD | Verb, past tense | went, played |\n",
    "| VBG | Verb, gerund | running, eating |\n",
    "| JJ | Adjective | happy, fast |\n",
    "| JJR | Comparative adjective | better, bigger |\n",
    "| RB | Adverb | quickly, silently |\n",
    "| DT | Determiner | the, an |\n",
    "| IN | Preposition | on, in, with |\n",
    "| PRP | Pronoun | he, she, they |\n",
    "| CC | Coordinating conjunction | and, but, or |\n",
    "| UH | Interjection | wow, oh |\n",
    "| . | Punctuation | ., ? |\n",
    "\n",
    "Full tag list is available with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52593d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('tagsets', quiet=True)\n",
    "nltk.download('tagsets_json', quiet=True)\n",
    "nltk.help.upenn_tagset()  # Shows all POS tag definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4ec66",
   "metadata": {},
   "source": [
    "## üßÆ 3. POS Tagging Process\n",
    "\n",
    "POS Tagging involves two main components:\n",
    "\n",
    "1. **Lexical lookup:**  \n",
    "   Assigns tags based on dictionary or training data.\n",
    "2. **Contextual disambiguation:**  \n",
    "   Uses the surrounding words to refine tags.\n",
    "\n",
    "$$\n",
    "\\text{POS}(w_i) = \\arg\\max_{t_j} P(t_j \\mid w_i, t_{i-1}, t_{i+1})\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ t_j $: possible POS tag for token $ w_i $\n",
    "- $ t_{i-1}, t_{i+1} $: neighboring tags\n",
    "\n",
    "This formula represents how **probabilistic POS taggers** (like HMM or CRF) decide tags contextually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f288c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence 1: \n",
      "When you step into any challenge, you must bring one thing above all ‚Äî consistency in your actions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "        When  ‚Üí  WRB\n",
      "         you  ‚Üí  PRP\n",
      "        step  ‚Üí  VBP\n",
      "        into  ‚Üí  IN\n",
      "         any  ‚Üí  DT\n",
      "   challenge  ‚Üí  NN\n",
      "           ,  ‚Üí  ,\n",
      "         you  ‚Üí  PRP\n",
      "        must  ‚Üí  MD\n",
      "       bring  ‚Üí  VB\n",
      "         one  ‚Üí  CD\n",
      "       thing  ‚Üí  NN\n",
      "       above  ‚Üí  IN\n",
      "         all  ‚Üí  DT\n",
      "           ‚Äî  ‚Üí  JJ\n",
      " consistency  ‚Üí  NN\n",
      "          in  ‚Üí  IN\n",
      "        your  ‚Üí  PRP$\n",
      "     actions  ‚Üí  NNS\n",
      "           .  ‚Üí  .\n",
      "\n",
      "Sentence 2: Success is not a sudden peak ‚Äî it‚Äôs a steady climb built on daily habits.\n",
      "-------------------------------------------------------------------------\n",
      "     Success  ‚Üí  NNP\n",
      "          is  ‚Üí  VBZ\n",
      "         not  ‚Üí  RB\n",
      "           a  ‚Üí  DT\n",
      "      sudden  ‚Üí  JJ\n",
      "        peak  ‚Üí  NN\n",
      "           ‚Äî  ‚Üí  NN\n",
      "          it  ‚Üí  PRP\n",
      "           ‚Äô  ‚Üí  VBZ\n",
      "           s  ‚Üí  VBZ\n",
      "           a  ‚Üí  DT\n",
      "      steady  ‚Üí  JJ\n",
      "       climb  ‚Üí  NN\n",
      "       built  ‚Üí  VBN\n",
      "          on  ‚Üí  IN\n",
      "       daily  ‚Üí  JJ\n",
      "      habits  ‚Üí  NNS\n",
      "           .  ‚Üí  .\n",
      "\n",
      "Sentence 3: You don‚Äôt wake up one morning and find you‚Äôre great; you become great because you kept showing up, kept trying, and kept learning.\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "         You  ‚Üí  PRP\n",
      "         don  ‚Üí  VBP\n",
      "           ‚Äô  ‚Üí  JJ\n",
      "           t  ‚Üí  NNS\n",
      "        wake  ‚Üí  VBP\n",
      "          up  ‚Üí  RP\n",
      "         one  ‚Üí  CD\n",
      "     morning  ‚Üí  NN\n",
      "         and  ‚Üí  CC\n",
      "        find  ‚Üí  VB\n",
      "         you  ‚Üí  PRP\n",
      "           ‚Äô  ‚Üí  JJ\n",
      "          re  ‚Üí  JJ\n",
      "       great  ‚Üí  JJ\n",
      "           ;  ‚Üí  :\n",
      "         you  ‚Üí  PRP\n",
      "      become  ‚Üí  VBP\n",
      "       great  ‚Üí  JJ\n",
      "     because  ‚Üí  IN\n",
      "         you  ‚Üí  PRP\n",
      "        kept  ‚Üí  VBD\n",
      "     showing  ‚Üí  VBG\n",
      "          up  ‚Üí  RP\n",
      "           ,  ‚Üí  ,\n",
      "        kept  ‚Üí  VBD\n",
      "      trying  ‚Üí  VBG\n",
      "           ,  ‚Üí  ,\n",
      "         and  ‚Üí  CC\n",
      "        kept  ‚Üí  VBD\n",
      "    learning  ‚Üí  NN\n",
      "           .  ‚Üí  .\n"
     ]
    }
   ],
   "source": [
    "# Example: POS tagging on MS Dhoni motivational paragraph\n",
    "paragraph = \"\"\"\n",
    "When you step into any challenge, you must bring one thing above all ‚Äî consistency in your actions.\n",
    "Success is not a sudden peak ‚Äî it‚Äôs a steady climb built on daily habits.\n",
    "You don‚Äôt wake up one morning and find you‚Äôre great; you become great because you kept showing up, kept trying, and kept learning.\n",
    "\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(paragraph)\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    tokens = word_tokenize(s)\n",
    "    tags = pos_tag(tokens)\n",
    "    print(f\"\\nSentence {i}: {s}\\n{'-'*len(s)}\")\n",
    "    for word, tag in tags:\n",
    "        print(f\"{word:>12}  ‚Üí  {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb405e1a",
   "metadata": {},
   "source": [
    "## üìò 4. Mapping POS Tags for Lemmatization\n",
    "\n",
    "As we saw earlier, WordNet uses a **simpler POS scheme**:\n",
    "- `wn.NOUN` (n)\n",
    "- `wn.VERB` (v)\n",
    "- `wn.ADJ` (a)\n",
    "- `wn.ADV` (r)\n",
    "\n",
    "We therefore need a conversion from **Penn Treebank ‚Üí WordNet** tags before lemmatization.\n",
    "\n",
    "$$\n",
    "\\text{map}(t_{Penn}) =\n",
    "\\begin{cases}\n",
    "n, & \\text{if starts with } N \\\\\n",
    "v, & \\text{if starts with } V \\\\\n",
    "a, & \\text{if starts with } J \\\\\n",
    "r, & \\text{if starts with } R\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc2d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NN ‚Üí n\n",
      " VBD ‚Üí v\n",
      "  JJ ‚Üí a\n",
      "  RB ‚Üí r\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    return wn.NOUN\n",
    "\n",
    "example_tags = ['NN', 'VBD', 'JJ', 'RB']\n",
    "for t in example_tags:\n",
    "    print(f\"{t:>4} ‚Üí {penn_to_wn(t)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1896e3",
   "metadata": {},
   "source": [
    "## üìä 5. POS Tag Distribution\n",
    "\n",
    "Let‚Äôs analyze the **frequency of POS tags** in our text to understand its structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552c87b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS Tag</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JJ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NNS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VBD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS Tag  Count\n",
       "10      JJ      9\n",
       "5       NN      8\n",
       "1      PRP      7\n",
       "3       IN      5\n",
       "2      VBP      4\n",
       "4       DT      4\n",
       "12     NNS      3\n",
       "6        ,      3\n",
       "21     VBD      3\n",
       "15     VBZ      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# POS distribution for Dhoni paragraph\n",
    "tokens = word_tokenize(paragraph)\n",
    "tags = pos_tag(tokens)\n",
    "tag_counts = Counter(tag for _, tag in tags)\n",
    "\n",
    "df_tags = pd.DataFrame(tag_counts.items(), columns=['POS Tag', 'Count']).sort_values(by='Count', ascending=False)\n",
    "df_tags.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd973f4",
   "metadata": {},
   "source": [
    "## üí° 6. Observations\n",
    "\n",
    "- Most frequent tags: **NN**, **VB**, **JJ**, and **RB** ‚Äî nouns, verbs, adjectives, adverbs.  \n",
    "- Indicates text is rich in **action (verbs)** and **motivation (adjectives/adverbs)**.\n",
    "- POS tagging enables:\n",
    "  - Context-aware **lemmatization**\n",
    "  - **Named Entity Recognition (NER)**\n",
    "  - **Dependency parsing**\n",
    "  - **Sentiment polarity analysis**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 7. Summary\n",
    "\n",
    "| Step | Description |\n",
    "|------|--------------|\n",
    "| **Tokenization** | Break text into words |\n",
    "| **POS Tagging** | Assign grammatical labels |\n",
    "| **Tag Mapping** | Convert Treebank ‚Üí WordNet |\n",
    "| **Use Cases** | Lemmatization, NER, Parsing, Sentiment |\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Final Thought\n",
    "\n",
    "> *‚ÄúUnderstanding language begins with understanding the role every word plays.‚Äù*  \n",
    "> ‚Äî *M.S. Dhoni-inspired NLP wisdom* üß¢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8254b",
   "metadata": {},
   "source": [
    "# üß≠ POS Tagging Flow\n",
    "\n",
    "**Inline math example:** $ \\text{POS}(w_i)=\\operatorname{tagger}(w_i, C_i) $,  \n",
    "and mapping to WordNet: $ \\text{map}(t_{\\text{Penn}})\\in\\{n,v,a,r\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "**Vertical flow (display math):**\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\boxed{\\text{Raw Text / Paragraph}} \\\\[6pt]\n",
    "\\Downarrow\\ \\text{sent\\_tokenize()} \\\\[6pt]\n",
    "\\boxed{\\text{Sentences } S_1,\\dots,S_n} \\\\[6pt]\n",
    "\\Downarrow\\ \\text{word\\_tokenize()} \\\\[6pt]\n",
    "\\boxed{\\text{Tokens } T_i=[w_{i1},\\dots,w_{im}]} \\\\[6pt]\n",
    "\\Downarrow\\ \\text{POS Tagger } \\text{tag}(w) \\\\[6pt]\n",
    "\\boxed{\\text{Penn POS Tags } \\{ \\text{NN},\\text{VB},\\text{JJ},\\text{RB},\\dots \\}} \\\\[6pt]\n",
    "\\Downarrow\\ \\text{map(Penn}\\!\\to\\!\\text{WordNet}) \\\\[6pt]\n",
    "\\boxed{\\text{WordNet POS } \\{n,v,a,r\\}} \\\\[6pt]\n",
    "\\Downarrow\\ \\text{Apply (e.g., Lemmatizer, Rules)} \\\\[6pt]\n",
    "\\boxed{\\text{Downstream Tasks: Lemma / NER / Parse / Sentiment}} \\\\[6pt]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Horizontal flow (compact):**\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Text}}\n",
    "\\xrightarrow{\\text{sent\\_tokenize}}\n",
    "\\boxed{\\text{Sentences}}\n",
    "\\xrightarrow{\\text{word\\_tokenize}}\n",
    "\\boxed{\\text{Tokens}}\n",
    "\\xrightarrow{\\text{POS Tagger}}\n",
    "\\boxed{\\text{Penn POS}}\n",
    "\\xrightarrow{\\text{map}}\n",
    "\\boxed{\\text{WN POS }(n,v,a,r)}\n",
    "\\xrightarrow{\\text{apply}}\n",
    "\\boxed{\\text{Lemmas / NER / Parse}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Core equations (display):**\n",
    "\n",
    "POS assignment with context window $C_i$:\n",
    "$$\n",
    "\\text{POS}(w_i)=\\arg\\max_{t\\in\\mathcal{T}} P\\!\\left(t \\mid w_i, C_i\\right)\n",
    "$$\n",
    "\n",
    "Penn $\\to$ WordNet mapping:\n",
    "$$\n",
    "\\text{map}(t)=\n",
    "\\begin{cases}\n",
    "n, & t\\ \\text{starts with } N \\\\[2pt]\n",
    "v, & t\\ \\text{starts with } V \\\\[2pt]\n",
    "a, & t\\ \\text{starts with } J \\\\[2pt]\n",
    "r, & t\\ \\text{starts with } R\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Applying POS-aware lemmatization:\n",
    "$$\n",
    "\\text{Lemma}(w,\\text{POS})=\\operatorname{lookup}_{\\text{WN}}\\!\\big(\\text{morph}(w),\\text{POS}\\big)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb395f",
   "metadata": {},
   "source": [
    "# üß≠ POS Tagging Flow ‚Äî Example with Dhoni‚Äôs Motivational Paragraph üèè\n",
    "\n",
    "We‚Äôll visualize the complete **POS tagging workflow** applied to our **MS Dhoni motivational paragraph**,  \n",
    "showing how each step transforms text ‚Äî from raw sentences to lemmatized words.  \n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Input Paragraph\n",
    "> ‚ÄúWhen you step into any challenge, you must bring one thing above all ‚Äî consistency in your actions.  \n",
    "> Success is not a sudden peak ‚Äî it‚Äôs a steady climb built on daily habits.  \n",
    "> You don‚Äôt wake up one morning and find you‚Äôre great; you become great because you kept showing up, kept trying, and kept learning.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Flowchart (LaTeX Visualization)\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\boxed{\\textbf{Raw Paragraph}} \\\\[6pt]\n",
    "\\text{\"When you step into any challenge, you must bring one thing above all ‚Äî consistency in your actions.\"} \\\\[8pt]\n",
    "\\Downarrow\\ \\text{sent\\_tokenize()} \\\\[6pt]\n",
    "\\boxed{\\textbf{Sentences } S_1, S_2, S_3} \\\\[6pt]\n",
    "\\text{S}_1=\\text{\"When you step into any challenge, you must bring one thing above all ‚Äî consistency in your actions.\"}\\\\[8pt]\n",
    "\\Downarrow\\ \\text{word\\_tokenize()} \\\\[6pt]\n",
    "\\boxed{\\textbf{Tokens for } S_1} \\\\[6pt]\n",
    "\\text{[\"When\",\"you\",\"step\",\"into\",\"any\",\"challenge\",\"you\",\"must\",\"bring\",\"one\",\"thing\",\"above\",\"all\",\"consistency\",\"in\",\"your\",\"actions\",\".\"]}\\\\[8pt]\n",
    "\\Downarrow\\ \\text{POS Tagger } \\text{tag}(w) \\\\[6pt]\n",
    "\\boxed{\\textbf{Penn POS Tags}} \\\\[6pt]\n",
    "\\text{When‚ÜíWRB, step‚ÜíVB, challenge‚ÜíNN, must‚ÜíMD, bring‚ÜíVB, thing‚ÜíNN, consistency‚ÜíNN, actions‚ÜíNNS}\\\\[8pt]\n",
    "\\Downarrow\\ \\text{map(Penn}\\!\\to\\!\\text{WordNet}) \\\\[6pt]\n",
    "\\boxed{\\textbf{Mapped WordNet POS}} \\\\[6pt]\n",
    "\\text{VB‚Üív,\\ NN‚Üín,\\ NNS‚Üín,\\ MD‚Üív,\\ WRB‚Üír}\\\\[8pt]\n",
    "\\Downarrow\\ \\text{POS-Aware Lemmatizer} \\\\[6pt]\n",
    "\\boxed{\\textbf{Lemmas}} \\\\[6pt]\n",
    "\\text{step‚Üístep,\\ bring‚Üíbring,\\ challenge‚Üíchallenge,\\ consistency‚Üíconsistency,\\ actions‚Üíaction}\\\\[8pt]\n",
    "\\Downarrow\\ \\text{Summarize / NLP Usage} \\\\[6pt]\n",
    "\\boxed{\\textbf{Downstream Applications}} \\\\[6pt]\n",
    "\\text{Lemmatization ‚úì \\quad NER ‚úì \\quad Sentiment ‚úì \\quad Parsing ‚úì}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Core Equations\n",
    "\n",
    "POS tagging as contextual prediction:\n",
    "$$\n",
    "\\text{POS}(w_i)=\\arg\\max_{t\\in\\mathcal{T}}P(t\\mid w_i,C_i)\n",
    "$$\n",
    "\n",
    "Penn ‚Üí WordNet mapping:\n",
    "$$\n",
    "\\text{map}(t_{\\text{Penn}})=\n",
    "\\begin{cases}\n",
    "n,&t\\text{ starts with }N\\\\[4pt]\n",
    "v,&t\\text{ starts with }V\\\\[4pt]\n",
    "a,&t\\text{ starts with }J\\\\[4pt]\n",
    "r,&t\\text{ starts with }R\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "POS-aware Lemmatization:\n",
    "$$\n",
    "\\text{Lemma}(w,\\text{POS})=\\operatorname{lookup}_{\\text{WN}}\\!\\big(\\text{morph}(w),\\text{POS}\\big)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary Table\n",
    "\n",
    "| Step | Function | Example Transformation (from Dhoni paragraph) |\n",
    "|------|-----------|-----------------------------------------------|\n",
    "| Sentence Tokenization | `sent_tokenize()` | Paragraph ‚Üí 3 sentences |\n",
    "| Word Tokenization | `word_tokenize()` | Sentence ‚Üí `[\"When\",\"you\",\"step\",...]` |\n",
    "| POS Tagging | `pos_tag()` | `step ‚Üí VB`, `challenge ‚Üí NN` |\n",
    "| POS Mapping | Penn ‚Üí WordNet | `VB ‚Üí v`, `NN ‚Üí n` |\n",
    "| Lemmatization | `lemmatizer.lemmatize()` | `actions ‚Üí action`, `bring ‚Üí bring` |\n",
    "| Summary | Merge results | Clean, lemmatized tokens ready for BoW/TF-IDF |\n",
    "\n",
    "---\n",
    "\n",
    "> üß¢ *‚ÄúIt‚Äôs not just about words ‚Äî it‚Äôs about what role each word plays.‚Äù*  \n",
    "> ‚Äî Inspired by **M.S. Dhoni**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
